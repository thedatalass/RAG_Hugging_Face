!pip install --user transformers datasets torch faiss-cpu wget
!pip install --user matplotlib scikit-learn

import wget
from transformers import DPRContextEncoder, DPRContextEncoderTokenizer
import torch

import numpy as np
import random
from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer
from transformers import AutoTokenizer, AutoModelForCausalLM


import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.manifold import TSNE
import numpy as np

# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

#DEFINE HELPER FUNCTIONS
def tsne_plot(data):
    # Apply t-SNE to reduce to 3D
    tsne = TSNE(n_components=3, random_state=42,perplexity=data.shape[0]-1)
    data_3d = tsne.fit_transform(data)
    
    # Plotting
    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111, projection='3d')
    
    # Assign colors for each point based on its index
    num_points = len(data_3d)
    colors = plt.cm.tab20(np.linspace(0, 1, num_points))
    
    # Plot scatter with unique colors for each point
    for idx, point in enumerate(data_3d):
        ax.scatter(point[0], point[1], point[2], label=str(idx), color=colors[idx])
    
    # Adding labels and titles
    ax.set_xlabel('TSNE Component 1')
    ax.set_ylabel('TSNE Component 2')
    ax.set_zlabel('TSNE Component 3')
    plt.title('3D t-SNE Visualization')
    plt.legend(title='Input Order')
    plt.show()

#LOAD/PREPROCESS DATA
filename = 'companyPolicies.txt' #txt file has to be loaded in same directory
url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'

# Use wget to download the file
wget.download(url, out=filename)
print('file downloaded')

#CONVERT SAVED PDF TO TXT FILE
pip install pymupdf
import fitz  # PyMuPDF

def pdf_to_text(pdf_path, txt_path):
    # Open the PDF file
    pdf_document = fitz.open(pdf_path)
    
    # Initialize an empty string to hold the text
    text = ""
    
    # Iterate through each page
    for page_num in range(len(pdf_document)):
        page = pdf_document.load_page(page_num)
        text += page.get_text()
    
    # Write the text to a file
    with open(txt_path, 'w', encoding='utf-8') as txt_file:
        txt_file.write(text)

# Example usage
pdf_path = 'm2505.pdf'
txt_path = 'm2505.txt'
pdf_to_text(pdf_path, txt_path)

#READ AND PREPROCESS DATA BY READING PARAGRAPHS
def read_and_split_text(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        text = file.read()
    # Split the text into paragraphs (simple split by newline characters)
    paragraphs = text.split('\n')
    # Filter out any empty paragraphs or undesired entries
    paragraphs = [para.strip() for para in paragraphs if len(para.strip()) > 0]
    return paragraphs

# Read the text file and split it into paragraphs
paragraphs = read_and_split_text('m2505.txt')
paragraphs[0:10]

#Let's look at a few samples from the file
for i in range(4):
    print(f"sample: {i} paragraph: {paragraphs[i]} \n" )

#Building the retriever: Encoding and indexing
#TOKENIZATION
%%capture
context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')
context_tokenizer

#RELATED OUTPUT TO BERT
text = [("How are you?", "I am fine."), ("What's up?", "Not much.")]
print(text)

#1. View token indexes
tokens_info=context_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=256)
tokens_info

for s in tokens_info['input_ids']:
   print(context_tokenizer.convert_ids_to_tokens(s))

#2. Encoding
context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')

#shuffling samples so that the samples are not ordered based on the category they belong to
random.shuffle(paragraphs)

tokens=context_tokenizer( paragraphs[:20], return_tensors='pt', padding=True, truncation=True, max_length=256) 
tokens
outputs=context_encoder(**tokens)
outputs.pooler_output

#t-SNE (t-Distributed Stochastic Neighbor Embedding) is an effective method for visualizing high-dimensional data, making it particularly useful for analyzing outputs from DPRContextEncoder models. 
pip install tsne

